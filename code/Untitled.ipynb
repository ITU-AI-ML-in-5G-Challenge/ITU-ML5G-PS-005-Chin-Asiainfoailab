{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "\n",
    "def LSTM_model(trainx, trainy):\n",
    "    # use the train\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, activation = 'relu', return_sequences = True, input_shape=(trainx.shape[1], trainx.shape[2])))\n",
    "    model.add(LSTM(100, activation = 'relu'))\n",
    "    model.add(Dense(trainx.shape[2]))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # model.fit(trainx, trainy, epochs = 50, verbose=2, callbacks=[callbacks])\n",
    "    model.fit(trainx, trainy, epochs=5, verbose=2)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from itertools import chain\n",
    "import os\n",
    "# from param_lstm_model import LSTM_model\n",
    "from pandas import Series\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from numpy import subtract\n",
    "import sys\n",
    "import traceback\n",
    "import pickle\n",
    "\n",
    "# 将对象以二进制形式保存\n",
    "def save(filename, cls):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(cls, f)\n",
    "\n",
    "\n",
    "# 加载二进制形式的对象\n",
    "def load(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        cls = pickle.load(f)\n",
    "        return cls         \n",
    "\n",
    "\n",
    "def tokens_generate(key_para_dict):\n",
    "    # 从所有的param中提取出单词表\n",
    "    '''\n",
    "    :param key_para_dict: the format is {Exx:[textual parameter 1],[texual parameter 2],...}\n",
    "    :return: tokens: all the word tokens in the parameter value vector column\n",
    "    '''\n",
    "    text = []\n",
    "    new_key_para_dict = {}\n",
    "    for key, value in key_para_dict.items():\n",
    "        para1 = []\n",
    "        # extract the time part from values\n",
    "        # value是对于一个日志键的所有日志的参数向量组成的列表\n",
    "        for param in value:  # ['rhost=218.188.2.4', '0'], ['3', '8', '9', '3', '7']\n",
    "            # print(f\"value{value}\")\n",
    "            # print(f\"param: {param}\") [['rhost=220-135-151-1.hinet-ip.hinet.net', 'user=root'], '38937']\n",
    "            # sys.exit()\n",
    "            para2 = []\n",
    "            # param是对于每个日志的参数向量列表, i是该日志的参数1，2，3，4\n",
    "            for i in param:\n",
    "                i = re.sub('=|\\/|#|:|\\[|\\]|\\'|\\s+|\\.|\\-|\\(|\\)|rhost=|,', '', str(i))\n",
    "                text.append(i)\n",
    "                para2.append(i)\n",
    "            para1.append(para2)\n",
    "        new_key_para_dict[key] = para1\n",
    "\n",
    "    return new_key_para_dict\n",
    "\n",
    "def token_dict(new_key_para_dict):\n",
    "    # 将token单词转化为数字\n",
    "    token_encode_dict = {}\n",
    "    '''\n",
    "    :param new_key_para_dict: 键为日志键，值为参数列表\n",
    "    :return: token_encode_dict: the format is ['fawjeiajet';[32,45,65,..],...]\n",
    "    '''\n",
    "    # doc : https://keras.io/zh/preprocessing/text/\n",
    "    # build the dict about different value\n",
    "    for key, value in new_key_para_dict.items():\n",
    "        tokenizer = Tokenizer()\n",
    "        tokens = list(chain(*value))\n",
    "        tokenizer.fit_on_texts(tokens)\n",
    "        encoded_texts = tokenizer.texts_to_sequences(tokens)\n",
    "        # build the dict with tokens --> encoded_texts\n",
    "        token_encode_dict_tmp = {}\n",
    "        for token, encoded_text in zip(tokens, encoded_texts):\n",
    "            token_encode_dict_tmp[token] = encoded_text\n",
    "        # 去除其中为[]的，将其转化为[0]\n",
    "        for k, v in token_encode_dict_tmp.items():\n",
    "            if token_encode_dict_tmp[k] == []:\n",
    "                token_encode_dict_tmp[k] = [0]\n",
    "        token_encode_dict[key] = token_encode_dict_tmp\n",
    "\n",
    "    return token_encode_dict\n",
    "\n",
    "\n",
    "def map_vectors(token_encode_dict, logkey_dict):\n",
    "    logkey_dict_num = {}\n",
    "    for key, param in logkey_dict.items(): # param 为一个日志键的所有日志条目的参数组成的列表\n",
    "        p_tmp = []\n",
    "        for p in param:  # p为一个日志条目中的参数向量，p为数组\n",
    "            p = [token_encode_dict[key][i] for i in p]\n",
    "            p_tmp.append(p)\n",
    "        logkey_dict_num[key] = p_tmp\n",
    "    return logkey_dict_num\n",
    "\n",
    "\n",
    "# define the module to transform str into matrix\n",
    "# the string is like: '10635,[21, 85, 16, 18],[21, 85, 16, 18, 307, 308, 1],[356],[424],[207]'\n",
    "def save_log_para_array(dict, df_type):\n",
    "    new_dict = {}\n",
    "    for eventID, lists_raw in dict.items():\n",
    "        new_dict[eventID] = []\n",
    "#         print(f\"eventID:{eventID},list_raw: {lists_raw}\")\n",
    "        if len(lists_raw) == 0:\n",
    "            continue\n",
    "        numy = len(lists_raw[0])\n",
    "        list_array = np.empty(shape=[0, numy])\n",
    "        for param in lists_raw:  # param : [[4],[5]] 一条日志的参数向量\n",
    "            lists = list(chain.from_iterable(param)) # 将多维列表合并为一位列表 [4, 5]\n",
    "            new_dict[eventID].append(lists)\n",
    "            try:\n",
    "                list_array = np.append(list_array, [lists], axis=0)\n",
    "            except Exception as e:\n",
    "                # print(\"there is an error like:\", e)\n",
    "                pass\n",
    "        # print(f\"eventID:{eventID},list_raw: {new_dict[eventID]}\")\n",
    "        filename = f\"./tmpdata/EventNpy/{df_type}_{eventID}.npy\"\n",
    "        np.save(filename, list_array)\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def training_data_generate(params, n_steps):\n",
    "    '''\n",
    "    :param params: 一个日志键的所有日志条目参数组成的矩阵\n",
    "    :param n_steps: lstm的历史窗口大下\n",
    "    :return: X, Y\n",
    "    '''\n",
    "    print(\"------------\")\n",
    "    # print(params)\n",
    "    matrix = np.array(params)\n",
    "    # print(matrix)\n",
    "    X, Y = list(), list()\n",
    "    for i in range(matrix.shape[0]):\n",
    "        # 找到这个滑动窗口的最后一个下标\n",
    "        end_ix = i + n_steps\n",
    "        # check whether beyond the dataset\n",
    "        if end_ix > matrix.shape[0]-1:\n",
    "            break\n",
    "        try:\n",
    "            seq_x, seq_y = matrix[i:end_ix, :], matrix[end_ix,:]\n",
    "            X.append(seq_x)\n",
    "            Y.append(seq_y)\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            sys.exit()\n",
    "        #     print(111111111111111111)\n",
    "        #     print(i, end_ix)\n",
    "        #     print(params)\n",
    "        #     print(type(matrix))\n",
    "        #     print(matrix.shape)\n",
    "        #     print(222222222222222)\n",
    "        #     continue\n",
    "    # sys.exit()\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def mean_squared_error_modified(y_true, y_pred):\n",
    "    ''' 修改后的mse以计算平方误差\n",
    "    # https://zhuanlan.zhihu.com/p/83410946\n",
    "    :param y_true: the test y --- array\n",
    "    :param y_pred: the predict y --- array\n",
    "    :return: the mean of errors, the errors list\n",
    "    '''\n",
    "    # 计算两个值之间的差\n",
    "    d_matrix = subtract(y_true, y_pred)\n",
    "    # print(\"the d_matrix is:\", d_matrix)\n",
    "    mses = []\n",
    "    # define the sum of minus\n",
    "    sum_minus = 0\n",
    "    # compute mse for every row\n",
    "    for i in range(d_matrix.shape[0]):\n",
    "        # 计算每一行的MSE\n",
    "        mse = np.mean(d_matrix[i]**2)\n",
    "        mses.append(mse)\n",
    "    return mses\n",
    "\n",
    "def param_value(df_train_log, df_test_log):\n",
    "\n",
    "\n",
    "    # 加载train数据和test数据\n",
    "    key_para_dict_train, logkey_lineid_dict_train, key_para_dict_test, logkey_lineid_dict_test = get_para_dict(df_train_log, df_test_log)\n",
    "\n",
    "\n",
    "    # 对train数据进行训练\n",
    "    model_dict = model_generate(key_para_dict_train)\n",
    "\n",
    "\n",
    "    # 对test数据进行异常检测\n",
    "    anormal_lineid_list = []\n",
    "    for eventID, params in key_para_dict_test.items():\n",
    "        n_steps = 3\n",
    "        # 如果test的日志键还没有模型生成，那么跳过对此日志键的检测\n",
    "        if eventID not in model_dict.keys():\n",
    "            continue\n",
    "        # 如果检测日志的同日志键的日志条目个数小于n_steps，则跳过检测，因为数据太少，一个滑动窗口都没有\n",
    "        elif len(params) < n_steps:\n",
    "            continue\n",
    "        else:\n",
    "            X_test, Y_test = training_data_generate(params, n_steps)\n",
    "            yhat = model_dict[eventID].predict(X_test)\n",
    "            mses = mean_squared_error_modified(Y_test, yhat)\n",
    "            print(f\"日志键：{eventID}，param异常检测结果：{mses}\")\n",
    "            for i in range(len(mses)):\n",
    "                # 如果大于阈值，则认为是异常的，这时候溯源到具体日志，保存在df_anormal中\n",
    "                if mses[i] > 1000:\n",
    "                    lineid = logkey_lineid_dict_test[eventID][i+3]\n",
    "                    anormal_lineid_list.append(lineid)\n",
    "\n",
    "    df_anormal = df_test_log.loc[df_test_log[\"LineId\"].isin(anormal_lineid_list)]\n",
    "    df_anormal.to_csv(\"para_anormal.csv\", index=False)\n",
    "\n",
    "\n",
    "def get_para_dict(df_train_log, df_test_log):\n",
    "\n",
    "    # 首先遍历所有的logkey，找出logkey的种类\n",
    "    logkey_list = list(set([EventId for EventId in df_train_log[\"EventId\"]]).union(set([EventId for EventId in df_test_log[\"EventId\"]])))\n",
    "\n",
    "    # 初始化一些字典，实际上是从df_log中提取出来的\n",
    "    logkey_param_dict_train = {}  # 键为log_key, 值为参数数组\n",
    "    logkey_content_dict_train = {}  # 键为log_key，值为log Content组成的的数组\n",
    "    logkey_lineid_dict_train = {}  # 键为log_key，值为df_type中的ids，用来异常溯源\n",
    "    logkey_param_dict_test = {}  # 键为log_key, 值为参数数组\n",
    "    logkey_content_dict_test = {}  # 键为log_key，值为log Content组成的的数组\n",
    "    logkey_lineid_dict_test = {}  # 键为log_key，值为df_type中的ids，用来异常溯源\n",
    "\n",
    "    logkey_param_dict = {}  # 将train和test里面的参数合并，键为log key，值为参数列表\n",
    "    # 对字典进行初始化\n",
    "    for key in logkey_list:\n",
    "        logkey_param_dict_train[key] = []\n",
    "        logkey_content_dict_train[key] = []\n",
    "        logkey_lineid_dict_train[key] = []\n",
    "        logkey_param_dict_test[key] = []\n",
    "        logkey_content_dict_test[key] = []\n",
    "        logkey_lineid_dict_test[key] = []\n",
    "        logkey_param_dict[key] = []\n",
    "\n",
    "\n",
    "    # 遍历df_train_log，将需要的数据依次添加到上述字典中\n",
    "    for id in range(len(df_train_log)):\n",
    "        log_key_tmp = df_train_log[\"EventId\"][id]\n",
    "        logkey_param_dict[log_key_tmp].append(df_train_log[\"ParameterList\"][id])\n",
    "        logkey_param_dict_train[log_key_tmp].append(df_train_log[\"ParameterList\"][id])\n",
    "        logkey_content_dict_train[log_key_tmp].append(df_train_log[\"Content\"][id])\n",
    "        logkey_lineid_dict_train[log_key_tmp].append(df_train_log[\"LineId\"][id])\n",
    "\n",
    "    # 遍历df_test_log，将需要的数据依次添加到上述字典中\n",
    "    for id in range(len(df_test_log)):\n",
    "        log_key_tmp = df_test_log[\"EventId\"][id]\n",
    "        logkey_param_dict[log_key_tmp].append(df_test_log[\"ParameterList\"][id])\n",
    "        logkey_param_dict_test[log_key_tmp].append(df_test_log[\"ParameterList\"][id])\n",
    "        logkey_content_dict_test[log_key_tmp].append(df_test_log[\"Content\"][id])\n",
    "        logkey_lineid_dict_test[log_key_tmp].append(df_test_log[\"LineId\"][id])\n",
    "\n",
    "    # 对参数字符进行一定处理，去除一些符号\n",
    "    new_key_para_dict = tokens_generate(logkey_param_dict)\n",
    "    new_key_para_dict_train = tokens_generate(logkey_param_dict_train)\n",
    "    new_key_para_dict_test = tokens_generate(logkey_param_dict_test)\n",
    "\n",
    "    # 建立一个字典，字典的键为日志键，值为一个字典（键为字符串，值为数字）\n",
    "    token_encode_dict = token_dict(new_key_para_dict)\n",
    "\n",
    "    # logkey_param_dict_train和logkey_param_dict_test\n",
    "    # num_key_para_dict_train 为字典，键为logkey，值为该logkey对应日志条目的数字形式参数列表\n",
    "    num_key_para_dict_train = map_vectors(token_encode_dict, new_key_para_dict_train)\n",
    "\n",
    "    num_key_para_dict_test = map_vectors(token_encode_dict, new_key_para_dict_test)\n",
    "\n",
    "    #  将一个日志条目中的多维列表合并为一维，并以矩阵形式保存在npy文件中\n",
    "    num_key_para_dict_train = save_log_para_array(num_key_para_dict_train, df_type='train')\n",
    "    num_key_para_dict_test = save_log_para_array(num_key_para_dict_test, df_type='train')\n",
    "\n",
    "\n",
    "\n",
    "    # 以下没什么作用，只是用来保存上述字典\n",
    "    # logkey_dict 键为eventID，值为log param组成的数组\n",
    "    df_dict_para = pd.DataFrame(dict([(k, Series(v)) for k, v in logkey_param_dict_train.items()]))\n",
    "    df_dict_para.to_csv(f\"./tmpdata/ParamData/train_param.csv\", index=False)\n",
    "    df_dict_para = pd.DataFrame(dict([(k, Series(v)) for k, v in logkey_param_dict_test.items()]))\n",
    "    df_dict_para.to_csv(f\"./tmpdata/ParamData/test_param.csv\", index=False)\n",
    "\n",
    "    # logkey_content_dict 键为eventID，值为log Content条目组成的数组\n",
    "    df_dict_para = pd.DataFrame(dict([(k, Series(v)) for k, v in logkey_content_dict_train.items()]))\n",
    "    df_dict_para.to_csv(f\"./tmpdata/ParamData/train_Content.csv\", index=False)\n",
    "    df_dict_para = pd.DataFrame(dict([(k, Series(v)) for k, v in logkey_content_dict_test.items()]))\n",
    "    df_dict_para.to_csv(f\"./tmpdata/ParamData/test_Content.csv\", index=False)\n",
    "\n",
    "\n",
    "    # num_key_para_dict 键为eventID，值为log param数字形式\n",
    "    df_dict_para = pd.DataFrame(dict([(k, Series(v)) for k, v in num_key_para_dict_train.items()]))\n",
    "    df_dict_para.to_csv(f\"./tmpdata/ParamData/train_param_num.csv\", index=False)\n",
    "    df_dict_para = pd.DataFrame(dict([(k, Series(v)) for k, v in num_key_para_dict_test.items()]))\n",
    "    df_dict_para.to_csv(f\"./tmpdata/ParamData/test_param_num.csv\", index=False)\n",
    "\n",
    "\n",
    "    return num_key_para_dict_train, logkey_lineid_dict_train, num_key_para_dict_test, logkey_lineid_dict_test\n",
    "\n",
    "# 对每个日志键组成的日志参数向量来lstm训练，将结果保存在tmpdata/ParamModel文件夹中\n",
    "def model_generate(key_para_dict):\n",
    "    # 对每个日志键进行训练，模型放在model_dict中，eventID为键，model为值\n",
    "    model_dict = {}\n",
    "    # 依次加载每个日志键的日志参数组成的矩阵，依次检测\n",
    "    for eventID, params in key_para_dict.items():\n",
    "        model_file = f\"ParamModel/{eventID}.pkl\"\n",
    "        if os.path.exists(model_file):\n",
    "            model_dict[eventID] = load(model_file)\n",
    "            continue\n",
    "\n",
    "        # 如果这个日志键对应的日志条目少于8个，则跳过对该日志键的模型生成\n",
    "        if len(params) <= 8:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            # 设置滑动窗口大小为3\n",
    "            n_steps = 3\n",
    "            X, Y = training_data_generate(params, n_steps)\n",
    "            model = LSTM_model(X, Y)\n",
    "            model_dict[eventID] = model\n",
    "            save(model_file, model)\n",
    "            # yhat = model.predict(test_x)\n",
    "            # print(\"the predicted y shapeis:\", yhat.shape)  # (4, 2)\n",
    "            # print(\"the test y shape is:\", test_y.shape)  # (4, 2)\n",
    "            # # 测量实际值和预测值的均方误差\n",
    "            # mses = mean_squared_error_modified(test_y, yhat)\n",
    "            # print(f\"mses: {mses}\")\n",
    "            # sys.exit()\n",
    "    return model_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_sys_train = pd.read_csv('df_sys_train.csv')\n",
    "df_sys_test = pd.read_csv('df_sys_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数值向量异常检测\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:273: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:279: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:286: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-ddd504c67b73>\", line 135, in training_data_generate\n",
      "    seq_x, seq_y = matrix[i:end_ix, :], matrix[end_ix,:]\n",
      "IndexError: too many indices for array\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# 参数值向量异常检测\n",
    "print(\"参数值向量异常检测\")\n",
    "# from param_value_detect import param_value\n",
    "\n",
    "df_sys_test_param = df_sys_test[df_sys_test.EventId.isin(df_sys_train.EventId.unique().tolist() )]\n",
    "df_sys_test_param.reset_index(drop=True,inplace=True)\n",
    "param_value(df_sys_train, df_sys_test_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_log = df_sys_train\n",
    "df_test_log = df_sys_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logkey_list = list(set([EventId for EventId in df_train_log[\"EventId\"]]).union(set([EventId for EventId in df_test_log[\"EventId\"]])))\n",
    "\n",
    "# 初始化一些字典，实际上是从df_log中提取出来的\n",
    "logkey_param_dict_train = {}  # 键为log_key, 值为参数数组\n",
    "logkey_content_dict_train = {}  # 键为log_key，值为log Content组成的的数组\n",
    "logkey_lineid_dict_train = {}  # 键为log_key，值为df_type中的ids，用来异常溯源\n",
    "logkey_param_dict_test = {}  # 键为log_key, 值为参数数组\n",
    "logkey_content_dict_test = {}  # 键为log_key，值为log Content组成的的数组\n",
    "logkey_lineid_dict_test = {}  # 键为log_key，值为df_type中的ids，用来异常溯源\n",
    "\n",
    "logkey_param_dict = {}  # 将train和test里面的参数合并，键为log key，值为参数列表\n",
    "# 对字典进行初始化\n",
    "for key in logkey_list:\n",
    "    logkey_param_dict_train[key] = []\n",
    "    logkey_content_dict_train[key] = []\n",
    "    logkey_lineid_dict_train[key] = []\n",
    "    logkey_param_dict_test[key] = []\n",
    "    logkey_content_dict_test[key] = []\n",
    "    logkey_lineid_dict_test[key] = []\n",
    "    logkey_param_dict[key] = []\n",
    "\n",
    "\n",
    "# 遍历df_train_log，将需要的数据依次添加到上述字典中\n",
    "for id in range(len(df_train_log)):\n",
    "    log_key_tmp = df_train_log[\"EventId\"][id]\n",
    "    logkey_param_dict[log_key_tmp].append(df_train_log[\"ParameterList\"][id])\n",
    "    logkey_param_dict_train[log_key_tmp].append(df_train_log[\"ParameterList\"][id])\n",
    "    logkey_content_dict_train[log_key_tmp].append(df_train_log[\"Content\"][id])\n",
    "    logkey_lineid_dict_train[log_key_tmp].append(df_train_log[\"LineId\"][id])\n",
    "\n",
    "# 遍历df_test_log，将需要的数据依次添加到上述字典中\n",
    "for id in range(len(df_test_log)):\n",
    "    log_key_tmp = df_test_log[\"EventId\"][id]\n",
    "    logkey_param_dict[log_key_tmp].append(df_test_log[\"ParameterList\"][id])\n",
    "    logkey_param_dict_test[log_key_tmp].append(df_test_log[\"ParameterList\"][id])\n",
    "    logkey_content_dict_test[log_key_tmp].append(df_test_log[\"Content\"][id])\n",
    "    logkey_lineid_dict_test[log_key_tmp].append(df_test_log[\"LineId\"][id])\n",
    "\n",
    "# 对参数字符进行一定处理，去除一些符号\n",
    "new_key_para_dict = tokens_generate(logkey_param_dict)\n",
    "new_key_para_dict_train = tokens_generate(logkey_param_dict_train)\n",
    "new_key_para_dict_test = tokens_generate(logkey_param_dict_test)\n",
    "\n",
    "# 建立一个字典，字典的键为日志键，值为一个字典（键为字符串，值为数字）\n",
    "token_encode_dict = token_dict(new_key_para_dict)\n",
    "\n",
    "# logkey_param_dict_train和logkey_param_dict_test\n",
    "# num_key_para_dict_train 为字典，键为logkey，值为该logkey对应日志条目的数字形式参数列表\n",
    "num_key_para_dict_train = map_vectors(token_encode_dict, new_key_para_dict_train)\n",
    "\n",
    "num_key_para_dict_test = map_vectors(token_encode_dict, new_key_para_dict_test)\n",
    "\n",
    "#  将一个日志条目中的多维列表合并为一维，并以矩阵形式保存在npy文件中\n",
    "num_key_para_dict_train = save_log_para_array(num_key_para_dict_train, df_type='train')\n",
    "num_key_para_dict_test = save_log_para_array(num_key_para_dict_test, df_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_key_para_dict_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'key_para_dict_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-62c13ca5b200>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkey_para_dict_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'key_para_dict_test' is not defined"
     ]
    }
   ],
   "source": [
    "key_para_dict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "for eventID, lists_raw in num_key_para_dict_test.items():\n",
    "    new_dict[eventID] = []\n",
    "#         print(f\"eventID:{eventID},list_raw: {lists_raw}\")\n",
    "    try:\n",
    "        numy = len(lists_raw[0])\n",
    "    except:\n",
    "        print(eventID)\n",
    "        print(lists_raw)\n",
    "        \n",
    "#     list_array = np.empty(shape=[0, numy])\n",
    "#     for param in lists_raw:  # param : [[4],[5]] 一条日志的参数向量\n",
    "#         lists = list(chain.from_iterable(param)) # 将多维列表合并为一位列表 [4, 5]\n",
    "#         new_dict[eventID].append(lists)\n",
    "#         try:\n",
    "#             list_array = np.append(list_array, [lists], axis=0)\n",
    "#         except Exception as e:\n",
    "#             # print(\"there is an error like:\", e)\n",
    "#             pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:271: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:273: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:277: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:279: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:284: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:286: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-ddd504c67b73>\", line 135, in training_data_generate\n",
      "    seq_x, seq_y = matrix[i:end_ix, :], matrix[end_ix,:]\n",
      "IndexError: too many indices for array\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "key_para_dict_train, logkey_lineid_dict_train, key_para_dict_test, logkey_lineid_dict_test = get_para_dict(df_train_log, df_test_log)\n",
    "\n",
    "\n",
    "# 对train数据进行训练\n",
    "model_dict = model_generate(key_para_dict_train)\n",
    "\n",
    "\n",
    "# 对test数据进行异常检测\n",
    "anormal_lineid_list = []\n",
    "for eventID, params in key_para_dict_test.items():\n",
    "    n_steps = 3\n",
    "    # 如果test的日志键还没有模型生成，那么跳过对此日志键的检测\n",
    "    if eventID not in model_dict.keys():\n",
    "        continue\n",
    "    # 如果检测日志的同日志键的日志条目个数小于n_steps，则跳过检测，因为数据太少，一个滑动窗口都没有\n",
    "    elif len(params) < n_steps:\n",
    "        continue\n",
    "    else:\n",
    "        X_test, Y_test = training_data_generate(params, n_steps)\n",
    "        yhat = model_dict[eventID].predict(X_test)\n",
    "        mses = mean_squared_error_modified(Y_test, yhat)\n",
    "        print(f\"日志键：{eventID}，param异常检测结果：{mses}\")\n",
    "        for i in range(len(mses)):\n",
    "            # 如果大于阈值，则认为是异常的，这时候溯源到具体日志，保存在df_anormal中\n",
    "            if mses[i] > 1000:\n",
    "                lineid = logkey_lineid_dict_test[eventID][i+3]\n",
    "                anormal_lineid_list.append(lineid)\n",
    "\n",
    "df_anormal = df_test_log.loc[df_test_log[\"LineId\"].isin(anormal_lineid_list)]\n",
    "df_anormal.to_csv(\"para_anormal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_para_dict_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_para_dict_train_new = {}\n",
    "for k, v in key_para_dict_train.items():\n",
    "    if len(v) != 0:\n",
    "        key_para_dict_train_new[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-ddd504c67b73>\", line 135, in training_data_generate\n",
      "    seq_x, seq_y = matrix[i:end_ix, :], matrix[end_ix,:]\n",
      "IndexError: too many indices for array\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_dict = model_generate(key_para_dict_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1ecb34ef8438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 如果test的日志键还没有模型生成，那么跳过对此日志键的检测\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0meventID\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# 如果检测日志的同日志键的日志条目个数小于n_steps，则跳过检测，因为数据太少，一个滑动窗口都没有\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_dict' is not defined"
     ]
    }
   ],
   "source": [
    "for eventID, params in key_para_dict_test.items():\n",
    "    n_steps = 3\n",
    "    # 如果test的日志键还没有模型生成，那么跳过对此日志键的检测\n",
    "    if eventID not in model_dict.keys():\n",
    "        continue\n",
    "    # 如果检测日志的同日志键的日志条目个数小于n_steps，则跳过检测，因为数据太少，一个滑动窗口都没有\n",
    "    elif len(params) < n_steps:\n",
    "        continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-ddd504c67b73>\", line 135, in training_data_generate\n",
      "    seq_x, seq_y = matrix[i:end_ix, :], matrix[end_ix,:]\n",
      "IndexError: too many indices for array\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_dict = model_generate(key_para_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
